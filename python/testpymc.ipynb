{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Framework\n",
      "=========\n",
      "\n",
      "Normal linear regression where the model, $M$, is also a random variable. We are interested in the posterior distribution of $M$. For an outcome $Y$ we have the following conditional distribution:\n",
      "\n",
      "$Y|X_m,M,\\theta_m \\sim \\mathcal{N}(X_m\\beta_m,\\sigma_m^2)$\n",
      "\n",
      ", where $X_m$ is a subvector of the full set of predictors $X$ and $\\theta_m = (\\beta_m, \\sigma_m)$ are parameters for model $M=m$, such that\n",
      "$\\beta_m$ are regression coefficients on $X_m$ and $\\sigma_m^2$ is the variance.\n",
      "\n",
      "The posterior distribution of $M$ is as follows:\n",
      "\n",
      "$$\n",
      "Pr(M=m|Y,X) = \\frac{Pr(Y|X_m,M)Pr(M=m|X)}{\\sum_{m' \\in \\mathcal{M}}Pr(Y|X_{m'},M=m')Pr(M=m'|X)}\n",
      "$$\n",
      "\n",
      "\n",
      ", where $Pr(Y|X_m,M)$ is the likelihood and $Pr(M=m|X)$ is the prior probability of a particular model $m$. The likelihood is an *integrated* likelihood:\n",
      "\n",
      "$$\n",
      "Pr(Y|X_m,M) = \\int_{\\Theta_m}Pr(Y|X_m,M,\\theta_m)Pr(\\theta_m|X_m,M)d\\theta_m\n",
      "$$\n",
      "\n",
      ", which requires a prior on the parameters $Pr(\\theta_m|X_m,M)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Setting Distributions and Empirical Simplifications\n",
      "===================================================\n",
      "\n",
      "Likelihood\n",
      "----------\n",
      "Instead of estimating the *integrated* likelihood we choose a simple approximation, which uses the bayesian information criterion (BIC).\n",
      "\n",
      "$Pr(Y|X_m,M) = exp(\\frac{1}{2}BIC_m)$\n",
      "\n",
      ", where \n",
      "\n",
      "$BIC_m \\approx logPr(Y|X_m,M,\\hat{\\theta}_m) - \\frac{|\\theta_m|}{2}log(n)$\n",
      "\n",
      ", where\n",
      "\n",
      "$logPr(Y|X_m,M,\\hat{\\theta}_m) = \\sum_{i=1}^nlog\\phi_i(Y_i)$\n",
      "\n",
      ", where each $\\phi$ is a normal pdf with mean $X_{m,i}\\hat{\\beta}_m$ and \n",
      "variance $\\hat{\\sigma}_m^2$. These parameters are the typical OLS estimates. Hence, by using the BIC, we do not specify the prior for the parameters, because the error in the approximation includes the prior.\n",
      "\n",
      "Model Prior\n",
      "-----------\n",
      "The prior is improper and takes the following form:\n",
      "\n",
      "$Pr(M=m|X) = det(R_{X_m})\\prod_{k=1}^K\\pi_k^{\\delta_k}(1-\\pi_k)^{1-\\delta_k}$\n",
      "\n",
      ", where $\\delta_k=1$ if regressor $k$ is in $X_m$ (0 otherwise), $\\pi_k$ is a hyperparameter (we will set to 0.5) which denotes the prior probability of including a variable in the model. Thus, our prior is simply:\n",
      "\n",
      "$Pr(M=m|X) = det(R_{X_m})0.5^K$\n",
      "\n",
      "Estimation of Posterior Model Probability\n",
      "-----------------------------------------\n",
      "The posterior is estimated up to some proportionality constant. Otherwise, we would have to 1) estimate all of the models in $\\mathcal{M}$ and 2) specify a proper model prior.\n",
      "\n",
      "$Pr(M=m|Y,X) \\propto Pr(Y|X_m,M)Pr(M=m|X)$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using PyMC to Sample from the Posterior Model Distribution\n",
      "==========================================================\n",
      "\n",
      "\n",
      "\n",
      "Example with Simulated Data\n",
      "---------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pymc import MCMC\n",
      "import bma_model\n",
      "import numpy as np\n",
      "import statsmodels.api as sm\n",
      "\n",
      "M = MCMC(bma_model)\n",
      "M.use_step_method(bma_model.ModelMetropolis, bma_model.regression_model)\n",
      "M.sample(iter=10000, burn=5000, thin=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[****************100%******************]  10000 of 10000 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_chain = M.trace(\"regression_model\")[:]\n",
      "\n",
      "counts = np.bincount(model_chain)\n",
      "freq = zip(counts[np.nonzero(counts)[0]], np.nonzero(counts)[0])\n",
      "freq.sort(reverse=True)\n",
      "\n",
      "import pandas as pd\n",
      "modes = list(pd.Series(model_chain).mode())\n",
      "for f in freq[:5]:\n",
      "    mode = f[1]\n",
      "    print('mode:',mode,bma_model.models[mode], f[0])\n",
      "    print(np.array([1. if i in bma_model.models[mode] else 0 for i in range(0,bma_model.rank)]))\n",
      "    print(bma_model.coefficients.flatten())\n",
      "    X = sm.add_constant(bma_model.x[:,bma_model.models[mode]], prepend=True)\n",
      "    print(X.shape)\n",
      "    fit = sm.OLS(bma_model.y, X).fit()\n",
      "    print(fit.params)\n",
      "    print(fit.rsquared)\n",
      "    print(\" \")\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('mode:', 464, [1, 2, 3, 5, 9], 7)\n",
        "[ 0.  1.  1.  1.  0.  1.  0.  0.  0.  1.]\n",
        "[ 0.  0.  0.  2.  0.  0.  0.  0.  0.  2.]\n",
        "(100, 6)\n",
        "[ 5.07747165 -0.03043406  0.02209928  1.99650815 -0.02483753  1.9312438 ]\n",
        "0.974953155897\n",
        " \n",
        "('mode:', 392, [0, 2, 3, 5, 7], 7)\n",
        "[ 1.  0.  1.  1.  0.  1.  0.  1.  0.  0.]\n",
        "[ 0.  0.  0.  2.  0.  0.  0.  0.  0.  2.]\n",
        "(100, 6)\n",
        "[ 10.05913668   0.50226705   0.04766066   1.79977853   0.02016216\n",
        "   0.74802705]\n",
        "0.40149163678\n",
        " \n",
        "('mode:', 551, [2, 4, 5, 8, 9], 6)\n",
        "[ 0.  0.  1.  0.  1.  1.  0.  0.  1.  1.]\n",
        "[ 0.  0.  0.  2.  0.  0.  0.  0.  0.  2.]\n",
        "(100, 6)\n",
        "[ 11.59209494  -0.04565559   0.12069434   0.08801388   0.44872903\n",
        "   1.86685611]\n",
        "0.58467060816\n",
        " \n",
        "('mode:', 546, [2, 4, 5, 6, 7], 6)\n",
        "[ 0.  0.  1.  0.  1.  1.  1.  1.  0.  0.]\n",
        "[ 0.  0.  0.  2.  0.  0.  0.  0.  0.  2.]\n",
        "(100, 6)\n",
        "[  2.30024984e+01  -5.51499565e-03   1.71431566e-01   5.62575739e-02\n",
        "  -1.58885998e-01   8.51707458e-01]\n",
        "0.0691472124604\n",
        " \n",
        "('mode:', 214, [1, 2, 4, 9], 6)\n",
        "[ 0.  1.  1.  0.  1.  0.  0.  0.  0.  1.]\n",
        "[ 0.  0.  0.  2.  0.  0.  0.  0.  0.  2.]\n",
        "(100, 5)\n",
        "[ 17.34907487  -0.06555837  -0.07688343   0.09368052   1.8333748 ]\n",
        "0.571215742204\n",
        " \n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}